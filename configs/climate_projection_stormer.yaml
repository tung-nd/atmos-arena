seed_everything: 42

# ---------------------------- TRAINER -------------------------------------------
trainer:
  default_root_dir: /path/to/root_dir

  precision: 16

  devices: null
  num_nodes: 1
  accelerator: gpu
  strategy: ddp

  min_epochs: 1
  max_epochs: 50
  enable_progress_bar: true

  sync_batchnorm: True
  enable_checkpointing: True
  num_sanity_val_steps: 1

  # debugging
  fast_dev_run: false

  logger:
    class_path: lightning.pytorch.loggers.wandb.WandbLogger
    init_args:
      project: 'atmos-arena'
      save_dir: ${trainer.default_root_dir}/climatebench_stormer_no_pooling_freeze_backbone_32bs_5e-4_lr
      name: climatebench_stormer_no_pooling_freeze_backbone_32bs_5e-4_lr

  callbacks:
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: "step"

    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "${trainer.default_root_dir}/climatebench_stormer_no_pooling_freeze_backbone_32bs_5e-4_lr/checkpoints"
        monitor: "val/w_mse" # name of the logged metric which determines when model is improving
        mode: "min" # "max" means higher metric value is better, can be also "min"
        save_top_k: 1 # save k best models (determined by above metric)
        save_last: True # additionaly always save model from last epoch
        verbose: False
        filename: "epoch_{epoch:03d}"
        auto_insert_metric_name: False

    - class_path: lightning.pytorch.callbacks.EarlyStopping
      init_args:
        monitor: "val/w_mse" # name of the logged metric which determines when model is improving
        mode: "min" # "max" means higher metric value is better, can be also "min"
        patience: 10 # how many validation epochs of not improving until training stops
        min_delta: 0. # minimum change in the monitored metric needed to qualify as an improvement

    - class_path: lightning.pytorch.callbacks.RichModelSummary
      init_args:
        max_depth: -1

    - class_path: lightning.pytorch.callbacks.TQDMProgressBar

# ---------------------------- MODEL -------------------------------------------
model:
  lr: 5e-4
  beta_1: 0.9
  beta_2: 0.999
  weight_decay: 1e-5
  warmup_epochs: 5
  max_epochs: 50
  warmup_start_lr: 1e-8
  eta_min: 1e-8
  pretrained_path: https://huggingface.co/tungnd/stormer/resolve/main/stormer_1.40625_patch_size_2.ckpt

  net:
    class_path: climate_projection.stormer_climatebench_arch.StormerClimateBench
    init_args:
      in_img_size: [32, 64]
      in_variables: [
        'CO2',
        'SO2',
        'CH4',
        'BC'
      ]
      out_variables: "tas" # diurnal_temperature_range, tas, pr, pr90
      time_history: 10
      patch_size: 2
      embed_norm: True
      hidden_size: 1024
      depth: 24
      num_heads: 16
      mlp_ratio: 4
      freeze_encoder: True

# ---------------------------- DATA -------------------------------------------
data:
  root_dir: /path/to/data
  history: 10
  list_train_simu: [
    'ssp126',
    'ssp370',
    'ssp585',
    'historical',
    'hist-GHG',
    'hist-aer'
  ]
  list_test_simu: ['ssp245']
  variables: [
      'CO2',
      'SO2',
      'CH4',
      'BC'
  ]
  out_variables: 'tas'
  train_ratio: 0.9
  batch_size: 8
  num_workers: 1
  pin_memory: False